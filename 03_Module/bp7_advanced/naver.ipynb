{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import joblib\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0        id                                           document  \\\n",
       "0           0   9976970                                  아 더빙 진짜 짜증나네요 목소리   \n",
       "1           1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나   \n",
       "2           2  10265843                                  너무재밓었다그래서보는것을추천한다   \n",
       "3           3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정   \n",
       "4           4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9976970</td>\n      <td>아 더빙 진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3819312</td>\n      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>9045019</td>\n      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>6483659</td>\n      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_df = pd.read_csv('../../../machine-Learning/00.data/naverMovie/train.tsv',\n",
    "                 sep='\\t')\n",
    "#train_df = train_df.drop(['id'], axis=1, inplace=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0       id                                   document  label\n",
       "0           0  6270596                                        굳 ㅋ      1\n",
       "1           2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
       "2           3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
       "3           4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0\n",
       "4           5  7898805                          음악이 주가 된 최고의 음악영화      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>6270596</td>\n      <td>굳 ㅋ</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>8544678</td>\n      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>6825595</td>\n      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>6723715</td>\n      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>7898805</td>\n      <td>음악이 주가 된 최고의 음악영화</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "test_df= pd.read_csv('../../../machine-Learning/00.data/naverMovie/test.tsv',\n",
    "                 sep='\\t')\n",
    "test_df.head()"
   ]
  },
  {
   "source": [
    "형태소 분석>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = [ '의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']  # 안에꺼 빠진상태로 돌림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=48995.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5430df3542194d3b8151c31de02f679b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "X_test = []\n",
    "for sentence in tqdm_notebook(test_df['document']):\n",
    "    morphs = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = ' '.join([word for word in morphs if not word in stopwords]) # 불용어 제거\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=145791.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebfb3ad1ff2e40c7b8cdb558ad4d7b4c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "X_train = []\n",
    "for sentence in tqdm_notebook(train_df['document']):    \n",
    "    morphs = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    \n",
    "    temp_X =' '.join([word for word in morphs if not word in stopwords]) # 불용어 제거\n",
    "    X_train.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "source": [
    "Case 1. CountVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cvecter = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "cvecter.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "params = ({\n",
    "    'count_vect__ngram_range': [(1,1), (1,2)],\n",
    "    'count_vect__max_df': [0.9, 0.95, 1],\n",
    "    'lr_clf__C': [1, 3, 5, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'count_vect__max_df': 0.9, 'count_vect__ngram_range': (1, 2), 'lr_clf__C': 1} 0.8416157375969711\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline1, param_grid=params, cv=3,\n",
    "                         scoring='accuracy')\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8463720787835494"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "best_count_lr = grid_pipe.best_estimator_\n",
    "pred_count_lr = best_count_lr.predict(X_test)\n",
    "accuracy_score(y_test, pred_count_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/Npipeline_cl.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "joblib.dump(best_count_lr, '../static/model/Npipeline_cl.pkl')"
   ]
  },
  {
   "source": [
    "Case 2. TfidfVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english',ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf_vect__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf_vect__max_df': [300, 700],\n",
    "    'lr_clf__C': [1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 28.1 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf_vect',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('lr_clf', LogisticRegression(C=10))])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "%time pipeline2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  4.0min finished\n",
      "{'lr_clf__C': 10, 'tfidf_vect__max_df': 700, 'tfidf_vect__ngram_range': (1, 2)} 0.8205307597862693\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline2, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8463720787835494"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "best_tfidf_lr = grid_pipe.best_estimator_\n",
    "pred_tfidf_lr = best_tfidf_lr.predict(X_test)\n",
    "accuracy_score(y_test, pred_tfidf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/Npipeline_tl.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "joblib.dump(best_tfidf_lr, '../static/model/Npipeline_tl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "source": [
    "Case 3. CountVectorizer + MultinomialNB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline3= Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('nv_clf', MultinomialNB())\n",
    "])\n",
    "params = {\n",
    "    'count_vect__ngram_range': [ (1,2)],\n",
    "    'count_vect__max_df': [0.9,0.99]}\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 8.61 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('nv_clf', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "%time pipeline3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   41.9s finished\n",
      "{'count_vect__max_df': 0.9, 'count_vect__ngram_range': (1, 2)} 0.8422056231180252\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline3, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8441881824675987"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "best_count_cn = pipeline3\n",
    "pred_count_cn = best_count_cn.predict(X_test)\n",
    "accuracy_score(y_test, pred_count_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/Npipeline_cn.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "joblib.dump(best_count_cn, '../static/model/Npipeline_cn.pkl')"
   ]
  },
  {
   "source": [
    "Case 4. TfidfVectorizer + MultinomialNB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline4 = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('nv_clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf_vect__ngram_range': [ (1,2)],\n",
    "    'tfidf_vect__max_df': [0.9,0.99]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 9.25 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf_vect',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('nv_clf', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "%time pipeline4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   44.3s finished\n",
      "{'tfidf_vect__max_df': 0.9, 'tfidf_vect__ngram_range': (1, 2)} 0.8433785350261677\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline4, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1) #, n_jobs=-1)\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8460251046025105"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "best_tfidf_nv = pipeline4\n",
    "pred_tfidf_nv = best_tfidf_nv.predict(X_test)\n",
    "accuracy_score(y_test, pred_tfidf_nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/Npipeline_tn.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "joblib.dump(best_tfidf_nv, '../static/model/Npipeline_tn.pkl')"
   ]
  },
  {
   "source": [
    "테스트>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cl = joblib.load('../static/model/Npipeline_cl.pkl')\n",
    "model_tl = joblib.load('../static/model/Npipeline_tl.pkl')\n",
    "model_cn = joblib.load('../static/model/Npipeline_cn.pkl')\n",
    "model_tn = joblib.load('../static/model/Npipeline_tn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "test_data = []\n",
    "test_data.append(test_df.iloc[index, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "pred_cl = model_cl.predict(test_data)\n",
    "pred_cl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 1, 1, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "pred_cl = model_cl.predict(test_data)\n",
    "pred_cn = model_cn.predict(test_data)\n",
    "pred_tl = model_tl.predict(test_data)\n",
    "pred_tn = model_tn.predict(test_data)\n",
    "pred_cl[0], pred_cn[0], pred_tl[0],  pred_tn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'진짜 개 노잼 이다 편이 랑 같은 감독 맞나 러닝 타임 도 길어서 개 지루함 ㄹㅇ'"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "review2 = '진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ '\n",
    "review2= re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\",review2)\n",
    "morphs =okt.morphs(review2)\n",
    "review2 = ' '.join([word for word in morphs if not word in stopwords])\n",
    "review2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_data.append(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "pred_cl = model_cl.predict(test_data)\n",
    "pred_cn = model_cn.predict(test_data)\n",
    "pred_tl = model_tl.predict(test_data)\n",
    "pred_tn = model_tn.predict(test_data)\n",
    "pred_cl[0], pred_cn[0], pred_tl[0] , pred_tn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = '진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1= re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\",review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'진짜 개 노잼 이다 편이 랑 같은 감독 맞나 러닝 타임 도 길어서 개 지루함 ㄹㅇ'"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "morphs =okt.morphs(review1)\n",
    "review1 = ' '.join([word for word in morphs if not word in stopwords])\n",
    "review1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8264312684967854"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "cvecter = CountVectorizer()\n",
    "cvecter.fit(X_train)\n",
    "X_train_cvect = cvecter.transform(X_train)\n",
    "X_test_cvect = cvecter.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cvect, y_train)\n",
    "pred = lr_clf.predict(X_test_cvect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cvect = cvecter.transform([review1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "pred = lr_clf.predict(review_cvect)\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_data.append(review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "pred_cl = model_cl.predict(test_data)\n",
    "pred_cn = model_cn.predict(test_data)\n",
    "pred_tl = model_tl.predict(test_data)\n",
    "pred_tn = model_tn.predict(test_data)\n",
    "pred_cl[0], pred_cn[0], pred_tl[0] , pred_tn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.append(df.iloc[index,2]) # test_data.append(df.loc[index,'document']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "test_df.label[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}